{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Pull Comments"
      ],
      "metadata": {
        "id": "ExqBG7nOSzQZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tunisian_Series_Comments_in_data_frame**"
      ],
      "metadata": {
        "id": "KE3kco7iAg3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import googleapiclient.discovery\n",
        "import pandas as pd\n",
        "\n",
        "api_service_name = \"youtube\"\n",
        "api_version = \"v3\"\n",
        "DEVELOPER_KEY = \"AIzaSyCn9KOD7zFTOaWCVHNkzsubK06XvpzXpDI\"\n",
        "\n",
        "youtube = googleapiclient.discovery.build(\n",
        "    api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
        "\n",
        "video_ids = [\"HupI3KwpQVM\",\"Iuc8En4sMPs\",\"Iuc8En4sMPs\",\"GuIGUiX8dms\",\"qYHXNe2T0gY\",\"mDFd1J1pYJM\",\"jC8DXuzxuMU\",\"dCTLTawoO40\",\"seKFnI2i4Lc\",\"xn8qsWa2CtM\" ]\n",
        "\n",
        "all_comments = []\n",
        "\n",
        "for video_id in video_ids:\n",
        "    next_page_token = None\n",
        "    while True:\n",
        "        request = youtube.commentThreads().list(\n",
        "            part=\"snippet\",\n",
        "            videoId=video_id,\n",
        "            maxResults=2000,  # 100 is the maximum allowed per request\n",
        "            pageToken=next_page_token\n",
        "        )\n",
        "        response = request.execute()\n",
        "\n",
        "        for item in response['items']:\n",
        "            comment = item['snippet']['topLevelComment']['snippet']\n",
        "            all_comments.append([\n",
        "                comment['authorDisplayName'],\n",
        "                comment['publishedAt'],\n",
        "                comment['updatedAt'],\n",
        "                comment['likeCount'],\n",
        "                comment['textDisplay']\n",
        "            ])\n",
        "\n",
        "        if 'nextPageToken' in response:\n",
        "            next_page_token = response['nextPageToken']\n",
        "        else:\n",
        "            break\n",
        "\n",
        "df = pd.DataFrame(all_comments, columns=['author', 'published_at', 'updated_at', 'like_count', 'text'])\n",
        "df_sorted = df.sort_values(by='like_count', ascending=False)\n",
        "\n",
        "print(df.head(30))\n",
        "print(df.info())\n",
        "print(df_sorted.head(30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLiMBpwG2rD-",
        "outputId": "8d593e0f-1528-473d-a479-06111198e438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                  author          published_at            updated_at  \\\n",
            "0      @Clubjasser-ps9fn  2024-04-01T01:22:44Z  2024-04-01T01:22:44Z   \n",
            "1          @SouSou-vu4zs  2024-03-30T22:56:43Z  2024-03-30T22:56:43Z   \n",
            "2       @user-vq5dm5xl3z  2024-03-29T20:27:31Z  2024-03-29T20:27:31Z   \n",
            "3   @SaharAbdallah-br2vt  2024-03-22T11:04:33Z  2024-03-22T11:04:33Z   \n",
            "4       @user-el8tu7zo2y  2024-03-02T18:42:43Z  2024-03-02T18:42:43Z   \n",
            "5      @hocinegrinat2160  2024-02-05T18:43:37Z  2024-02-05T18:43:37Z   \n",
            "6             @Mimou9611  2023-12-27T23:42:53Z  2023-12-27T23:42:53Z   \n",
            "7            @YAZAN..540  2023-11-23T16:16:01Z  2023-11-23T16:16:01Z   \n",
            "8      @mohamedsidani925  2023-11-14T14:29:45Z  2023-11-14T14:29:45Z   \n",
            "9       @user-si8oi4ik1h  2023-10-19T10:28:56Z  2023-10-19T10:28:56Z   \n",
            "10        @takwancib8321  2023-07-15T13:06:37Z  2023-07-15T13:06:37Z   \n",
            "11      @moniatouibi7663  2023-06-11T13:24:22Z  2023-06-11T13:24:22Z   \n",
            "12      @hayetannabi5648  2023-06-10T22:24:36Z  2023-06-10T22:24:36Z   \n",
            "13       @feryalista7359  2023-06-07T16:57:34Z  2023-06-07T16:57:34Z   \n",
            "14      @user-wc4go4mo5y  2023-06-02T21:03:28Z  2023-06-02T21:05:26Z   \n",
            "15     @chourouktlili626  2023-06-01T21:52:36Z  2023-06-01T21:52:36Z   \n",
            "16      @fouziatoumi9490  2023-05-31T05:28:48Z  2023-05-31T05:28:48Z   \n",
            "17       @polatfranc7967  2023-05-20T21:46:01Z  2023-05-20T21:46:01Z   \n",
            "18      @user-dl6yl8by5j  2023-05-20T17:44:38Z  2023-05-20T17:44:38Z   \n",
            "19      @raniacherif5210  2023-05-20T10:47:31Z  2023-05-20T10:47:31Z   \n",
            "20       @amelelkoni7441  2023-05-19T22:38:17Z  2023-05-19T22:38:17Z   \n",
            "21            @Yazidi65N  2023-05-19T18:11:24Z  2023-05-19T18:11:24Z   \n",
            "22      @amirameftah2166  2023-05-19T18:06:34Z  2023-05-19T18:06:34Z   \n",
            "23      @user-hw7iv5xq9k  2023-05-14T12:09:01Z  2023-05-14T12:09:01Z   \n",
            "24      @user-hw7iv5xq9k  2023-05-14T12:07:31Z  2023-05-14T12:07:31Z   \n",
            "25   @halloumasbouii9550  2023-05-13T19:12:47Z  2023-05-13T19:12:47Z   \n",
            "26      @user-vt7if9kr2i  2023-05-11T19:47:23Z  2023-05-11T19:47:23Z   \n",
            "27      @hanenkhahli4731  2023-05-10T16:08:07Z  2023-05-10T16:08:07Z   \n",
            "28     @soniahajfraj6822  2023-05-10T12:21:26Z  2023-05-10T12:21:26Z   \n",
            "29      @CoconutCharcoal  2023-05-08T10:21:54Z  2023-05-08T10:21:54Z   \n",
            "\n",
            "    like_count                                               text  \n",
            "0            0                                  ماسطة و تفاهة !!!  \n",
            "1            0                                               😂😂😂😂  \n",
            "2            0                  مش عارفه ليش صوتهم عالي التونسيات  \n",
            "3            0                                               Hh 😂  \n",
            "4            0                                    😂😂😂😊😊❤❤❤❤🥰🥰🤣😂🥺🥺  \n",
            "5            0                                               😂😂😂😂  \n",
            "6            0       😂😂😂😂محلاه سيتكوم اش خص كان يجيبوه في التلفزة  \n",
            "7            0                                  ملا امساطة😒😒😒😒😒😒😒  \n",
            "8            0                                       😂😂😂😂😂😂😂😂😂😂😂😂  \n",
            "9            0                                        محلاهم 😂😂😂😂  \n",
            "10           1  اروى انت ديما متألق في كل المسلسلات وخاصة اضحك...  \n",
            "11           0                                       Rak 3assssal  \n",
            "12           0                                            😂😂😂😂😂❤❤  \n",
            "13           0                          الليلة الكلبة en personne  \n",
            "14           0   ممسطها المخلوقة ومقبحها عمرو  التمثيل ما كان هكة  \n",
            "15           1                                  ❤❤❤❤❤❤bravo wasel  \n",
            "16           1                                  ممسطها   ياوخياتي  \n",
            "17           1                                        تفوه ممسطكم  \n",
            "18           0    😂😂😂😂❤❤❤❤❤❤😊😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂😂waw😮  \n",
            "19           0                                                ❤❤❤  \n",
            "20           3                   محلاها تهبل تحيه من ليبيا❤❤❤🤣🤣🤣🤣  \n",
            "21           7           محلاهم يقتلوا بضحك تمثيل باهي واصلوا 😂❤❤  \n",
            "22           0                                       ما امسطهاااا  \n",
            "23           0                                            😮😮😮😮😮😮😮  \n",
            "24           0                                           😅😅😅😅😅😅😅😅  \n",
            "25           2                                        Adorable 😂😂  \n",
            "26           0                                 ❤❤❤❤🎉🎉🎉🎉😂😂😂😂😊😊😊😊😊😊  \n",
            "27           1                                       تفاهة و غباء  \n",
            "28           0                                         Bravooo🎉🎉🎉  \n",
            "29           1                              teeeeeeeeeeeeeeeeefih  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2102 entries, 0 to 2101\n",
            "Data columns (total 5 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   author        2102 non-null   object\n",
            " 1   published_at  2102 non-null   object\n",
            " 2   updated_at    2102 non-null   object\n",
            " 3   like_count    2102 non-null   int64 \n",
            " 4   text          2102 non-null   object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 82.2+ KB\n",
            "None\n",
            "                               author          published_at  \\\n",
            "1527                          @klouvg  2020-04-27T20:23:32Z   \n",
            "916                  @user-ks2tv8bd6i  2020-04-26T00:54:11Z   \n",
            "549                     @zekiziko5457  2020-04-24T19:05:33Z   \n",
            "1002  @jihadessidlikemajdbelguith5252  2020-04-25T20:05:56Z   \n",
            "973                 @anouartanger5054  2020-04-25T21:00:39Z   \n",
            "948                       @SaSa-wj5yo  2020-04-25T22:25:25Z   \n",
            "1200                    @Alaadinalhaj  2020-04-27T05:09:21Z   \n",
            "467                 @oualidoualid3245  2020-04-25T07:29:52Z   \n",
            "978                  @karimgharbi9637  2020-04-25T20:47:33Z   \n",
            "463                    @touatieya4984  2020-04-25T10:21:27Z   \n",
            "540                  @newjourneyy1015  2020-04-24T19:46:39Z   \n",
            "475                    @ahmedsasi1680  2020-04-25T04:53:46Z   \n",
            "1470                      @pnlqlf2885  2020-04-28T00:56:03Z   \n",
            "1202                    @ninanano6874  2020-04-27T04:13:23Z   \n",
            "878                  @user-cf4iz8wd4r  2020-04-26T04:54:18Z   \n",
            "1492                  @sabri3aziza643  2020-04-27T22:34:39Z   \n",
            "1766               @oussamamellal7210  2020-04-28T23:19:15Z   \n",
            "1660                  @soniasmeti9271  2020-05-05T11:22:47Z   \n",
            "1284                  @aminebalti1657  2020-04-26T19:16:05Z   \n",
            "501                  @bennejiolfa5676  2020-04-24T23:00:57Z   \n",
            "1523                   @blelrchid9720  2020-04-27T20:35:16Z   \n",
            "1290                @beateviertel3770  2020-04-26T19:04:29Z   \n",
            "965                  @aishadababi2629  2020-04-25T21:19:11Z   \n",
            "58                     @habibanmj3352  2023-04-22T18:15:13Z   \n",
            "528                @udyigeoyekgsd3367  2020-04-24T20:38:55Z   \n",
            "2001                       @EVAN23338  2020-04-30T10:21:42Z   \n",
            "278                @yassminekallel483  2020-11-19T10:25:17Z   \n",
            "1810                    @wisalb.a7019  2020-04-28T21:02:46Z   \n",
            "1807                    @aimendou3960  2020-04-28T21:08:13Z   \n",
            "439                  @user-ks2tv8bd6i  2020-04-26T00:53:49Z   \n",
            "\n",
            "                updated_at  like_count  \\\n",
            "1527  2020-04-27T20:23:32Z         108   \n",
            "916   2020-04-26T00:54:11Z         106   \n",
            "549   2020-04-24T19:05:33Z         100   \n",
            "1002  2020-04-25T20:05:56Z          82   \n",
            "973   2020-04-25T21:00:39Z          75   \n",
            "948   2020-04-25T22:25:25Z          73   \n",
            "1200  2020-04-27T05:09:21Z          72   \n",
            "467   2020-04-25T07:29:52Z          70   \n",
            "978   2020-04-25T20:47:33Z          66   \n",
            "463   2020-04-25T10:21:27Z          64   \n",
            "540   2020-04-24T19:46:39Z          62   \n",
            "475   2020-04-25T04:53:46Z          59   \n",
            "1470  2020-04-28T00:56:03Z          58   \n",
            "1202  2020-04-27T04:13:23Z          58   \n",
            "878   2020-04-26T04:54:18Z          57   \n",
            "1492  2020-04-27T22:34:39Z          55   \n",
            "1766  2020-04-28T23:19:15Z          52   \n",
            "1660  2020-05-05T11:22:47Z          51   \n",
            "1284  2020-04-26T19:16:05Z          49   \n",
            "501   2020-04-24T23:00:57Z          49   \n",
            "1523  2020-04-27T20:35:16Z          48   \n",
            "1290  2020-04-26T19:04:29Z          45   \n",
            "965   2020-04-25T21:19:11Z          44   \n",
            "58    2023-04-22T18:15:13Z          43   \n",
            "528   2020-04-24T20:38:55Z          42   \n",
            "2001  2020-04-30T10:21:42Z          42   \n",
            "278   2020-11-19T10:25:17Z          41   \n",
            "1810  2020-04-28T21:02:46Z          40   \n",
            "1807  2020-04-28T21:08:13Z          39   \n",
            "439   2020-04-26T00:53:49Z          39   \n",
            "\n",
            "                                                   text  \n",
            "1527                   شكون لي قلق من السارق كي مهربش😂😂  \n",
            "916   كل شخص يقرأ الكومنتار هذا نقلو رمضانك مبروك ور...  \n",
            "549                               صحا فطوركم من الجزائر  \n",
            "1002  محلاه السيتكوم ضحكني انا جاني كوميدي السيتكوم ...  \n",
            "973         من المغرب ما احلاكم اخوننا التونسه والجزائر  \n",
            "948   صراحة جعفر كوميدي بالفطرة والملامح ههه تحية من...  \n",
            "1200  رمضان مبارك علي توانسه والجزائر والمغرب الكل<b...  \n",
            "467   صدقوني مستوى البرامج التونسية افضل من برامجنا ...  \n",
            "978   نشالله رمضانكم مبروك أحبابي و أصحابي ونشالله ن...  \n",
            "463   شكون يتفرج على دنيا أخرى ومبعد أولاد مفيدة ومب...  \n",
            "540            Generique mahleeh si lemhaf big up &lt;3  \n",
            "475   يخي وقته تصورت هذه تي كورونا جات عندها شهر كيف...  \n",
            "1470         ڨلڨت م السارق الي ڨلڨ يعمل لايك 💪💪⁦❤️⁩⁦❤️⁩  \n",
            "1202  حلقة روعة يعطيكم العافية تحية من الجزائر لإخوا...  \n",
            "878   Bravo Louled 5edma tayara 🔥<br>Denya o5ra = J&...  \n",
            "1492  الي يدخل بش يسمع الغناية و يعمل عليها جو يترشق...  \n",
            "1766  أحسن سيتكوم نتبعو نتاع الصح يوميا<br>تحية لكل ...  \n",
            "1660                           اشكون يتفرج فيه يضع لايك  \n",
            "1284                                حلقة اليوم عجبتني 😂  \n",
            "501                       برافو جعفور و كوثر الباردي ❤🤣  \n",
            "1523                                شكون قلق ماك السارق  \n",
            "1290                        جعفور، سفيان داهش 😂😂😂❤️❤️❤️  \n",
            "965             رووووعة السيتكوم والغناية تهبلني 🤣🤣😍😍💘💘  \n",
            "58    ممسطتها ها لمرا ياخي بالحق تعتبر ممثلة كوميدية...  \n",
            "528                                   لغناية مووووت ❤❤❤  \n",
            "2001  لي بيحط لايك الله يدخل للجنة والله يخليلو والد...  \n",
            "278       مسكين  وليد الزين عاد المسلسل كامل في الخزانة  \n",
            "1810                  صلّحلهم السّبّالة ولّى مالعايلة 😂  \n",
            "1807  يهبل السيتكوم فيه برررشة ضمار محلاهم الكل والل...  \n",
            "439   كل شخص يقرأ الكومنتار هذا نقلو رمضانك مبروك ور...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA PREPROCESSING**"
      ],
      "metadata": {
        "id": "g1PF9rMrGKi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_t=df['text']\n",
        "df_t=pd.DataFrame(df_t)\n",
        "df_t.duplicated().sum()\n",
        "#check the null values\n",
        "print(df_t.isnull().sum())\n",
        "#Check the duplicated  values :\n",
        "duplicate_rows = df_t[df_t.duplicated()]\n",
        "print(duplicate_rows)\n",
        "df_t = df_t.drop_duplicates()\n",
        "#delete the deplication\n",
        "print('le nombre de duplication egale:')\n",
        "print(df_t.duplicated().sum())\n",
        "print(df_t.info())"
      ],
      "metadata": {
        "id": "utmVZnFl3_vK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0697d25c-a316-4480-f325-48fc7fc058ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text    0\n",
            "dtype: int64\n",
            "                   text\n",
            "5                  😂😂😂😂\n",
            "82                 ❤❤❤❤\n",
            "94                 😂😂😂😂\n",
            "97                    ❤\n",
            "103               😅😅😅😅😅\n",
            "...                 ...\n",
            "2034           😂😂😂😂😂😂😂😂\n",
            "2082             هههههه\n",
            "2085        صحة شريبتكم\n",
            "2086  Bravo ahla sitkom\n",
            "2100          اول تعليق\n",
            "\n",
            "[151 rows x 1 columns]\n",
            "le nombre de duplication egale:\n",
            "0\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1951 entries, 0 to 2101\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    1951 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 30.5+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def remove_french_arabic_emoji(text):\n",
        "    \"\"\"Removes French comments, specific Arabic words, comments with only numbers, and emoji-only comments.\"\"\"\n",
        "    # Remove specific Arabic words\n",
        "    arabic_stopwords = r\"اروع|اجمل|أحلى|حبيت|اححببت|اعجبني|أعجبني|هايل|روعة|سفيان|يرحم|سفيان|حسونة|يرحمو\"  # Replace with your desired list of Arabic words\n",
        "    text = re.sub(arabic_stopwords, \"\", text)\n",
        "\n",
        "    # Remove comments containing only emojis\n",
        "    # This pattern matches sequences of one or more emoji characters\n",
        "    emoji_pattern = r\"[^\\u0000-\\u007F\\s]+?\"\n",
        "    is_emoji_only = re.fullmatch(emoji_pattern, text)\n",
        "    if is_emoji_only:\n",
        "        text = \"\"  # Replace emoji-only text with an empty string\n",
        "\n",
        "    # Check for comments containing only numbers\n",
        "    if text.isdigit():\n",
        "        text = \"\"  # Replace comments with only numbers with an empty string\n",
        "\n",
        "\n",
        "    # If any alphabetic characters are found, it's considered potentially French\n",
        "    if re.search(\"[A-Za-z]\", text):\n",
        "        text = \"\"  # Replace French text with an empty string\n",
        "\n",
        "    return text\n",
        "\n",
        "# Filter DataFrame\n",
        "df_t = df_t.applymap(remove_french_arabic_emoji)  # Apply the function to all columns\n",
        "df_t.dropna(inplace=True)\n",
        "\n",
        "# Print cleaned DataFrame\n",
        "print(df_t.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBDYifD7Guo7",
        "outputId": "7813205f-b5c3-4a54-96e2-9ecdb3c542f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1951 entries, 0 to 2101\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    1951 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 30.5+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_t.info())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYpsf5e6JZjV",
        "outputId": "1766e8d2-12ed-4767-a7e5-06a64b3f094b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1951 entries, 0 to 2101\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    1951 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 30.5+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we will clean our data form emojie"
      ],
      "metadata": {
        "id": "UMWUpEBjULV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will delete the comments that are not written in arabic and the comments that contains word شعري  سفيان حسونة  because it does not have any utility in our analysis"
      ],
      "metadata": {
        "id": "-1glTrnpQvSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparation of the data frame to the Notation"
      ],
      "metadata": {
        "id": "jbMcvTsfVSDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('les valeurs dupliquer sont')\n",
        "print(df_t.duplicated().sum())\n",
        "df_t= df_t.drop_duplicates()\n",
        "print(df_t.duplicated().sum())\n",
        "#check the null values\n",
        "print('les valeurs null number')\n",
        "print(df_t.isnull().sum())\n",
        "#Check the duplicated  values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUfgd3zQvLyd",
        "outputId": "2e7e3f1a-84f7-434f-e471-dd1c340decd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "les valeurs dupliquer sont\n",
            "948\n",
            "0\n",
            "les valeurs null number\n",
            "text    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_t['sentiment']=''\n",
        "df_t.to_csv('data_f.csv', index=False, encoding='utf-8')\n",
        "\n",
        "print(\"Data downloaded successfully.\")"
      ],
      "metadata": {
        "id": "4UU40RlpwVju",
        "outputId": "67908651-7c34-4264-9fc5-4d16a3f28167",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data downloaded successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-313012a30e33>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_t['sentiment']=''\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_t.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SaGi_2KLOVO",
        "outputId": "f4d39858-3d9e-474f-e1ce-46cc20af2834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 1003 entries, 0 to 2099\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   text       1003 non-null   object\n",
            " 1   sentiment  1003 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 23.5+ KB\n",
            "None\n"
          ]
        }
      ]
    }
  ]
}